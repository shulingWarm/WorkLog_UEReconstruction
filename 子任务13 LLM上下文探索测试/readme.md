# 目标
- 当用户对于LLM模型反馈的结果不满意时，可以用语言指出LLM回答不好的地方，模型根据玩家的反馈直接进行在线训练。
- 因为这里面涉及到超长的上下文，所以模型里面需要一些结构把这些内容都记忆下来。

# 工作过程
- [DONE] 开发一个LLMTrainer用于封装LLM的训练过程。
- [DONE] 准备用于训练的复杂提示词。
- [DOING] 训练LLM在简单提示词的情况下，输出和完整提示词质量一样的输出。
	- [DONE] 配置MS Swift，这是qwen3推荐的训练框架。
	- [DOING] 准备用于训练的数据集格式。
	- [TO-DO] 用lora训练qwen3-8b。
- [TO-DO] 研究目前最新的LLM模型的结构，看看在什么地方适合添加这种记忆模块。