# 目标
- 加速基于nunchaku推理的Qwen-Image-Edit。

# 工作过程
- [DONE] 从源码编译nunchaku。
	- 跳过pip，直接用python setup.py build_ext可以正常编译。
- [DONE] 测试nunchaku的主要时间瓶颈。
	- 89%的时间用于transformer block，全局50%的时间用于attention.
- [DONE] 将nunchaku的attention实现换成flash attention.
	- 将torch native attention换成flash attention后没有性能提升。
- [DONE] 为了定位flash-attention的具体实现，源码编译flash attention.
- [DONE] 在flash-attention源码里面定位实际执行的kernel。
- [DONE] 解耦flash-attention里面的关键kernel.
	- [DONE] 令解耦的flash-attention链接pytorch.
	- [DONE] 参考原本的flash-attention的头文件，在解耦的flash-attention中引用。
	- [DONE] 引用flash attention的核函数，仅带头文件编译完成。
	- [DONE] 解决带实际调用核函数时编译检查报错的问题。
- [DONE] Dump调用Qwen-Image-Edit时产生的实际attention输入数据，用于测试解耦kernel。
- [DONE] 根据运行Qwen-Image-Edit记录的attention数据数据，在解耦kernel里面执行测试。
- [DONE] 移植flash-attention仓库里面初始化param的过程。
- [DONE] 解决执行过程中产生非法内存访问导致程序异常结束的问题。
	- 需要将参数结构体中未使用到的指针明确指定成空指针。
- [DONE] 测试attention kernel内部不同阶段的占比。
	- 占比最多的是写入输出数据的操作，cute::copy，在kernel内占大概50%.
- [DONE] 定位flash-attention中的cute::copy的实现。
- [DONE] 写一个独立的kernel测试cute::copy，主要用于理解这个函数的输入输出形式。
	- [DONE] 调用make_tensor由外部指针创建一个tensor.
	- [DONE] 创建用于执行cute::copy的复制逻辑。
	- [DONE] 调用cute::copy。
	- 实现了对长度为8的简单向量的单线程复制并验证复制结果。
- [DONE] 追溯flash-attention里面调用的cute::copy实际执行复制逻辑的最底层代码。
- [DONE] 追溯执行复制的Tensor底层指针存储的位置。
	- 本质上是一个用unroll展开的循环。
- [DONE] 测试用Tensor底层的指针直接执行复制的效果。
	- 直接执行复制的速度在1000次执行attention后，时间从81xx降低到了80xx.
- [GIVE-UP] 子任务1 追溯cute::copy涉及到的数据来源
- [DONE] 验证执行复制output的cute::copy时候是否存在bank冲突。
	- [DONE] 验证发现每个线程从sO中取出的切片不能覆盖sO的所有数据。
	- [DONE] Debug研究sO切片的复制是有错误还是确实不需要完整复制。
		- 需要按照sO起始指针到读取位置来打印，数据是完整被复制过的。
	- [DONE] 根据每个线程打印的内容，确实存在bank冲突。
- [GIVE-UP] 按照每个线程一次读取4个字节来避免bank冲突。
	- [DONE] 准备每个线程用于存储local数据的头指针。
	- [DONE] 准备每个线程用于执行复制时在共享内存上的偏移量。
	- 验证发现cute::copy并不耗时，profile发现耗时是因为它用到了GEMM的计算结果。
- [DONE] 按照计算块重复的方式验证flash-attention里面最耗时的部分。
	- gemm_rs占用了flash-attention里面一半的时间。
- [DOING] 定位gemm_rs里面底层被执行的计算指令。
	- [DOING] 由于gemm执行层涉及多个if constexpr判断，需要根据tensor判断使用的是哪个分支。